#!/usr/bin/env python3
"""
NotebookLM ëŒ€ê·œëª¨ ì†ŒìŠ¤ ì—…ë¡œë“œ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸
600ê°œ ì†ŒìŠ¤ ìš©ëŸ‰ì„ ìµœëŒ€í•œ í™œìš©í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ê°œë³„ ì²­í¬ë¡œ ë¶„ë¦¬
"""
import json
import os
from pathlib import Path
from datetime import datetime

DATA_DIR = Path(__file__).parent.parent.parent / "data"
OUTPUT_DIR = DATA_DIR / "notebooklm_sources"
OUTPUT_DIR.mkdir(exist_ok=True)

def load_json(path: Path) -> list | dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def sanitize_filename(name: str) -> str:
    """íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ ì œê±°"""
    for char in ['/', '\\', ':', '*', '?', '"', '<', '>', '|', ' ']:
        name = name.replace(char, '_')
    return name

def save_source(filename: str, content: dict | str, category: str):
    """ì†ŒìŠ¤ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    category_dir = OUTPUT_DIR / category
    category_dir.mkdir(exist_ok=True)
    
    if isinstance(content, dict):
        text = json.dumps(content, ensure_ascii=False, indent=2)
    else:
        text = content
    
    with open(category_dir / filename, "w", encoding="utf-8") as f:
        f.write(text)
    
    return str(category_dir / filename)

def chunk_video_segments():
    """ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°œë³„ ì†ŒìŠ¤ë¡œ ë¶„ë¦¬"""
    segments = load_json(DATA_DIR / "bong_video_segments.json")
    sources = []
    
    for seg in segments:
        filename = f"{seg['segment_id']}.json"
        
        # í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        enriched = {
            **seg,
            "_source_type": "video_segment",
            "_cluster_id": "CL_BONG_01",
            "_description": f"ë´‰ì¤€í˜¸ - {seg.get('source_id', '')} - {seg.get('scene_id', '')}",
        }
        
        path = save_source(filename, enriched, "video_segments")
        sources.append(path)
    
    print(f"âœ… Video Segments: {len(sources)}ê°œ")
    return sources

def chunk_derived_insights():
    """íŒŒìƒ ì¸ì‚¬ì´íŠ¸ë¥¼ ê°œë³„ ì†ŒìŠ¤ë¡œ ë¶„ë¦¬"""
    insights = load_json(DATA_DIR / "bong_derived_insights.json")
    sources = []
    
    for i, insight in enumerate(insights):
        guide_type = insight.get("guide_type", "report")
        source_id = insight.get("source_id", f"insight_{i}")
        filename = f"{source_id}_{guide_type}.json"
        
        enriched = {
            **insight,
            "_source_type": "derived_insight",
            "_cluster_id": "CL_BONG_01",
        }
        
        path = save_source(filename, enriched, "derived_insights")
        sources.append(path)
        
        # ì¶”ê°€: ê° ë¹„íŠ¸ ê°œë³„ ì†ŒìŠ¤
        if "beats" in insight:
            for beat in insight["beats"]:
                beat_filename = f"{source_id}_beat_{beat['beat_id']}.json"
                beat_enriched = {
                    "source_id": source_id,
                    "beat": beat,
                    "_source_type": "beat_detail",
                    "_cluster_id": "CL_BONG_01",
                }
                path = save_source(beat_filename, beat_enriched, "beats")
                sources.append(path)
        
        # ì¶”ê°€: ê° ìƒ· ê°œë³„ ì†ŒìŠ¤ (ìŠ¤í† ë¦¬ë³´ë“œ)
        if "shots" in insight:
            for shot in insight["shots"]:
                shot_filename = f"{source_id}_shot_{shot['shot_number']}.json"
                shot_enriched = {
                    "source_id": source_id,
                    "shot": shot,
                    "_source_type": "shot_detail",
                    "_cluster_id": "CL_BONG_01",
                }
                path = save_source(shot_filename, shot_enriched, "shots")
                sources.append(path)
    
    print(f"âœ… Derived Insights: {len(sources)}ê°œ")
    return sources

def chunk_patterns():
    """íŒ¨í„´ì„ ê°œë³„ ì†ŒìŠ¤ë¡œ ë¶„ë¦¬"""
    patterns = load_json(DATA_DIR / "bong_pattern_candidates.json")
    sources = []
    
    for i, pattern in enumerate(patterns):
        safe_name = sanitize_filename(pattern['pattern_name'])
        filename = f"pattern_{safe_name}.json"
        
        enriched = {
            **pattern,
            "_source_type": "pattern_candidate",
            "_cluster_id": "CL_BONG_01",
        }
        
        path = save_source(filename, enriched, "patterns")
        sources.append(path)
    
    print(f"âœ… Patterns: {len(sources)}ê°œ")
    return sources

def chunk_ideal_guides():
    """Ideal ê°€ì´ë“œë¥¼ ê°œë³„ ì†ŒìŠ¤ë¡œ ë¶„ë¦¬"""
    ideal_dir = DATA_DIR / "ideal"
    sources = []
    
    for json_file in ideal_dir.glob("bong_*.json"):
        data = load_json(json_file)
        
        enriched = {
            **data,
            "_source_type": "ideal_guide",
            "_cluster_id": "CL_BONG_01",
        }
        
        path = save_source(json_file.name, enriched, "ideal_guides")
        sources.append(path)
        
        # ì„¸ë¶€ í•­ëª© ë¶„ë¦¬
        if "thematic_obsessions" in data:
            for obsession in data["thematic_obsessions"]:
                safe_name = sanitize_filename(obsession['theme'])
                filename = f"obsession_{safe_name}.json"
                path = save_source(filename, {
                    "auteur": data.get("auteur"),
                    "obsession": obsession,
                    "_source_type": "thematic_obsession",
                }, "obsessions")
                sources.append(path)
        
        if "signature_techniques" in data:
            # Visual techniques
            for tech in data["signature_techniques"].get("visual", []):
                safe_name = sanitize_filename(tech['name'])
                filename = f"tech_visual_{safe_name}.json"
                path = save_source(filename, {
                    "auteur": data.get("auteur"),
                    "technique": tech,
                    "category": "visual",
                    "_source_type": "signature_technique",
                }, "techniques")
                sources.append(path)
            
            # Narrative techniques
            for tech in data["signature_techniques"].get("narrative", []):
                safe_name = sanitize_filename(tech['name'])
                filename = f"tech_narrative_{safe_name}.json"
                path = save_source(filename, {
                    "auteur": data.get("auteur"),
                    "technique": tech,
                    "category": "narrative",
                    "_source_type": "signature_technique",
                }, "techniques")
                sources.append(path)
    
    print(f"âœ… Ideal Guides: {len(sources)}ê°œ")
    return sources

def chunk_raw_assets():
    """Raw Assetsë¥¼ ê°œë³„ ì†ŒìŠ¤ë¡œ ë¶„ë¦¬"""
    assets = load_json(DATA_DIR / "bong_raw_assets.json")
    sources = []
    
    for asset in assets:
        filename = f"asset_{asset['source_id']}.json"
        
        enriched = {
            **asset,
            "_source_type": "raw_asset",
            "_cluster_id": "CL_BONG_01",
        }
        
        path = save_source(filename, enriched, "raw_assets")
        sources.append(path)
    
    print(f"âœ… Raw Assets: {len(sources)}ê°œ")
    return sources

def chunk_existing_derived():
    """ì´ë¯¸ ì¶”ì¶œëœ derived ë°ì´í„°ë„ ì†ŒìŠ¤ë¡œ ì¶”ê°€"""
    derived_dir = DATA_DIR / "derived" / "bong"
    sources = []
    
    if derived_dir.exists():
        for json_file in derived_dir.glob("*.json"):
            data = load_json(json_file)
            
            enriched = {
                **data,
                "_source_type": "extracted_knowledge",
                "_extracted_from": "NotebookLM",
            }
            
            path = save_source(f"extracted_{json_file.name}", enriched, "extracted")
            sources.append(path)
    
    print(f"âœ… Extracted Knowledge: {len(sources)}ê°œ")
    return sources

def create_manifest(all_sources: list):
    """ì—…ë¡œë“œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
    manifest = {
        "created_at": datetime.now().isoformat(),
        "cluster_id": "CL_BONG_01",
        "director": "ë´‰ì¤€í˜¸",
        "total_sources": len(all_sources),
        "sources_by_category": {},
        "files": []
    }
    
    for path in all_sources:
        path_obj = Path(path)
        category = path_obj.parent.name
        
        if category not in manifest["sources_by_category"]:
            manifest["sources_by_category"][category] = 0
        manifest["sources_by_category"][category] += 1
        
        manifest["files"].append({
            "path": path,
            "category": category,
            "filename": path_obj.name
        })
    
    with open(OUTPUT_DIR / "upload_manifest.json", "w", encoding="utf-8") as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“‹ Manifest saved: {OUTPUT_DIR / 'upload_manifest.json'}")
    return manifest

def main():
    print("=" * 60)
    print("NotebookLM ëŒ€ê·œëª¨ ì†ŒìŠ¤ ì¤€ë¹„")
    print("=" * 60)
    
    all_sources = []
    
    # 1. Video Segments
    all_sources.extend(chunk_video_segments())
    
    # 2. Derived Insights (+ beats, shots)
    all_sources.extend(chunk_derived_insights())
    
    # 3. Patterns
    all_sources.extend(chunk_patterns())
    
    # 4. Ideal Guides (+ obsessions, techniques)
    all_sources.extend(chunk_ideal_guides())
    
    # 5. Raw Assets
    all_sources.extend(chunk_raw_assets())
    
    # 6. Already extracted
    all_sources.extend(chunk_existing_derived())
    
    # Create manifest
    manifest = create_manifest(all_sources)
    
    print("=" * 60)
    print(f"ğŸ“Š ì´ ì†ŒìŠ¤ ìˆ˜: {len(all_sources)}ê°œ")
    print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ë³„:")
    for cat, count in manifest["sources_by_category"].items():
        print(f"   - {cat}: {count}ê°œ")
    print("=" * 60)
    print(f"\nâœ… ëª¨ë“  ì†ŒìŠ¤ê°€ {OUTPUT_DIR}ì— ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("NotebookLMì— ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ê±°ë‚˜ APIë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
